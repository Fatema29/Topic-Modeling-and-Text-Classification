{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('abcnews-date-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short = df.copy()\n",
    "df_short = df_short.drop(['publish_date'], axis=1)\n",
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aba decides against community broadcasting licence'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_text'].dropna(inplace=True)\n",
    "#removing numbers from string\n",
    "df['headline_text'] = df['headline_text'].str.replace('\\d+', '')\n",
    "\n",
    "df['headline_text'] = [entry.lower() for entry in df['headline_text']]\n",
    "#df['headline']= [word_tokenize(entry) for entry in df['headline']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[aba, decid, against, commun, broadcast, licenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[act, fire, wit, must, be, awar, of, defam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[a, g, call, for, infrastructur, protect, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[air, nz, staff, in, aust, strike, for, pay, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[air, nz, strike, to, affect, australian, travel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219   [aba, decid, against, commun, broadcast, licenc]\n",
       "1      20030219        [act, fire, wit, must, be, awar, of, defam]\n",
       "2      20030219  [a, g, call, for, infrastructur, protect, summit]\n",
       "3      20030219  [air, nz, staff, in, aust, strike, for, pay, r...\n",
       "4      20030219  [air, nz, strike, to, affect, australian, travel]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "stemmer = PorterStemmer() \n",
    "  \n",
    "# stem words in the list of tokenised words \n",
    "def stem_words(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    return stems \n",
    "df2= df.copy()\n",
    "df2['headline_text'] = [stem_words(entry) for entry in df2['headline_text']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[aba, decid, commun, broadcast, licenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[act, fire, wit, must, awar, defam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[g, call, infrastructur, protect, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>[air, nz, strike, affect, australian, travel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                  headline_text\n",
       "0      20030219        [aba, decid, commun, broadcast, licenc]\n",
       "1      20030219            [act, fire, wit, must, awar, defam]\n",
       "2      20030219      [g, call, infrastructur, protect, summit]\n",
       "3      20030219      [air, nz, staff, aust, strike, pay, rise]\n",
       "4      20030219  [air, nz, strike, affect, australian, travel]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))                  \n",
    "#df2=df.copy()\n",
    "def remove_stops(row):\n",
    "    my_list = row['headline_text']\n",
    "    meaningful_words = [w for w in my_list if not w in stops]\n",
    "    return (meaningful_words)\n",
    "df3=df2.copy()\n",
    "df3['headline_text'] = df3.apply(remove_stops, axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decid, commun, broadcast, licenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, wit, must, awar, defam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[g, call, infrastructur, protect, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, affect, australian, travel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   headline_text\n",
       "0        [aba, decid, commun, broadcast, licenc]\n",
       "1            [act, fire, wit, must, awar, defam]\n",
       "2      [g, call, infrastructur, protect, summit]\n",
       "3      [air, nz, staff, aust, strike, pay, rise]\n",
       "4  [air, nz, strike, affect, australian, travel]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=df3.copy()\n",
    "df6= df6.drop(['publish_date'], axis=1)\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 aba\n",
      "1 broadcast\n",
      "2 commun\n",
      "3 decid\n",
      "4 licenc\n",
      "5 act\n",
      "6 awar\n",
      "7 defam\n",
      "8 fire\n",
      "9 must\n",
      "10 wit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df6['headline_text'])\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(151, 1), (560, 1), (1385, 1), (4636, 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df6['headline_text']]\n",
    "bow_corpus[4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5929540978827899),\n",
      " (1, 0.4753689825619525),\n",
      " (2, 0.3101866300328752),\n",
      " (3, 0.40056040343663335),\n",
      " (4, 0.4071429552006896)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.017*\"market\" + 0.013*\"tasmania\" + 0.012*\"price\" + 0.012*\"open\" + 0.011*\"share\" + 0.010*\"victoria\" + 0.009*\"island\" + 0.009*\"christma\" + 0.008*\"storm\" + 0.008*\"campaign\"\n",
      "Topic: 1 \n",
      "Words: 0.045*\"new\" + 0.013*\"council\" + 0.013*\"chang\" + 0.012*\"health\" + 0.011*\"say\" + 0.009*\"school\" + 0.009*\"indigen\" + 0.008*\"servic\" + 0.008*\"meet\" + 0.008*\"worker\"\n",
      "Topic: 2 \n",
      "Words: 0.036*\"polic\" + 0.022*\"man\" + 0.019*\"die\" + 0.019*\"crash\" + 0.018*\"car\" + 0.015*\"death\" + 0.013*\"investig\" + 0.012*\"woman\" + 0.011*\"driver\" + 0.011*\"attack\"\n",
      "Topic: 3 \n",
      "Words: 0.030*\"man\" + 0.026*\"court\" + 0.024*\"charg\" + 0.020*\"year\" + 0.020*\"murder\" + 0.019*\"interview\" + 0.018*\"face\" + 0.015*\"found\" + 0.013*\"accus\" + 0.012*\"sex\"\n",
      "Topic: 4 \n",
      "Words: 0.026*\"govern\" + 0.019*\"nsw\" + 0.017*\"rural\" + 0.014*\"qld\" + 0.014*\"say\" + 0.014*\"state\" + 0.013*\"nation\" + 0.011*\"labor\" + 0.010*\"protest\" + 0.010*\"support\"\n",
      "Topic: 5 \n",
      "Words: 0.025*\"australia\" + 0.020*\"trump\" + 0.019*\"win\" + 0.017*\"day\" + 0.014*\"one\" + 0.014*\"first\" + 0.012*\"coast\" + 0.010*\"gold\" + 0.009*\"test\" + 0.009*\"afl\"\n",
      "Topic: 6 \n",
      "Words: 0.021*\"queensland\" + 0.020*\"world\" + 0.017*\"countri\" + 0.015*\"hour\" + 0.014*\":\" + 0.014*\";\" + 0.012*\"cup\" + 0.011*\"record\" + 0.009*\"leagu\" + 0.009*\"australian\"\n",
      "Topic: 7 \n",
      "Words: 0.025*\"elect\" + 0.020*\"mine\" + 0.013*\"work\" + 0.010*\"peopl\" + 0.009*\"fire\" + 0.009*\"futur\" + 0.009*\"children\" + 0.008*\"say\" + 0.008*\"river\" + 0.007*\"rescu\"\n",
      "Topic: 8 \n",
      "Words: 0.024*\"kill\" + 0.018*\"live\" + 0.016*\"job\" + 0.014*\"road\" + 0.013*\"cut\" + 0.012*\"train\" + 0.011*\"wa\" + 0.010*\"violenc\" + 0.010*\"busi\" + 0.009*\"station\"\n",
      "Topic: 9 \n",
      "Words: 0.023*\"south\" + 0.020*\"north\" + 0.019*\"sydney\" + 0.017*\"miss\" + 0.015*\"west\" + 0.013*\"china\" + 0.013*\"polic\" + 0.012*\"news\" + 0.011*\"turnbul\" + 0.011*\"australia\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.4224846363067627\t \n",
      "Topic: 0.031*\"to\" + 0.023*\"in\" + 0.016*\"market\" + 0.013*\"live\" + 0.012*\"on\" + 0.012*\"rise\" + 0.011*\"farmer\" + 0.011*\"price\" + 0.011*\"tasmania\" + 0.010*\"rate\"\n",
      "\n",
      "Score: 0.4173772633075714\t \n",
      "Topic: 0.041*\"in\" + 0.031*\"the\" + 0.025*\"of\" + 0.024*\"australia\" + 0.019*\"to\" + 0.015*\"a\" + 0.014*\"for\" + 0.014*\"win\" + 0.013*\"out\" + 0.012*\"day\"\n",
      "\n",
      "Score: 0.020026937127113342\t \n",
      "Topic: 0.040*\"to\" + 0.037*\"for\" + 0.017*\"countri\" + 0.014*\"hour\" + 0.011*\"call\" + 0.009*\"of\" + 0.009*\"a\" + 0.009*\"more\" + 0.008*\"guilti\" + 0.008*\"tasmanian\"\n",
      "\n",
      "Score: 0.020018765702843666\t \n",
      "Topic: 0.061*\"to\" + 0.021*\"for\" + 0.016*\"rural\" + 0.015*\"north\" + 0.013*\"in\" + 0.011*\"fund\" + 0.011*\"health\" + 0.010*\"on\" + 0.009*\"say\" + 0.009*\"new\"\n",
      "\n",
      "Score: 0.02001785673201084\t \n",
      "Topic: 0.051*\"to\" + 0.039*\"be\" + 0.037*\"for\" + 0.012*\"in\" + 0.012*\"miss\" + 0.010*\"may\" + 0.010*\"protest\" + 0.010*\"have\" + 0.009*\"search\" + 0.008*\"of\"\n",
      "\n",
      "Score: 0.020016200840473175\t \n",
      "Topic: 0.029*\"of\" + 0.017*\"govern\" + 0.017*\"over\" + 0.015*\"about\" + 0.013*\"plan\" + 0.013*\"mine\" + 0.012*\"warn\" + 0.012*\"to\" + 0.012*\"water\" + 0.010*\"concern\"\n",
      "\n",
      "Score: 0.020015915855765343\t \n",
      "Topic: 0.033*\"on\" + 0.033*\"to\" + 0.020*\"for\" + 0.020*\"into\" + 0.018*\"coast\" + 0.014*\"the\" + 0.012*\"how\" + 0.012*\"gold\" + 0.011*\"an\" + 0.011*\"ban\"\n",
      "\n",
      "Score: 0.020014293491840363\t \n",
      "Topic: 0.063*\"in\" + 0.030*\"man\" + 0.026*\"after\" + 0.023*\"polic\" + 0.023*\"over\" + 0.023*\"of\" + 0.017*\"court\" + 0.017*\"charg\" + 0.014*\"at\" + 0.012*\"interview\"\n",
      "\n",
      "Score: 0.020014097914099693\t \n",
      "Topic: 0.023*\"of\" + 0.019*\"to\" + 0.016*\"elect\" + 0.016*\"for\" + 0.014*\"say\" + 0.014*\"on\" + 0.011*\"by\" + 0.011*\"trial\" + 0.011*\"labor\" + 0.010*\"over\"\n",
      "\n",
      "Score: 0.020014073699712753\t \n",
      "Topic: 0.059*\"the\" + 0.026*\":\" + 0.026*\"to\" + 0.020*\"and\" + 0.015*\"of\" + 0.014*\"is\" + 0.013*\"on\" + 0.011*\"back\" + 0.011*\"from\" + 0.010*\"island\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.21798069741739484\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.2756025676076595\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=35, id2word=dictionary)\n",
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.28771298038709\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=45, id2word=dictionary)\n",
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.29872410356567186\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=55, id2word=dictionary)\n",
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5929540978827899),\n",
      " (1, 0.4753689825619525),\n",
      " (2, 0.3101866300328752),\n",
      " (3, 0.40056040343663335),\n",
      " (4, 0.4071429552006896)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.021*\"trump\" + 0.019*\":\" + 0.010*\"australia\" + 0.009*\"day\" + 0.007*\"live\" + 0.007*\"world\" + 0.006*\"test\" + 0.006*\"energi\" + 0.006*\"win\" + 0.006*\"juli\"\n",
      "Topic: 1 Word: 0.022*\"man\" + 0.015*\"polic\" + 0.014*\"charg\" + 0.012*\"murder\" + 0.011*\"woman\" + 0.011*\"crash\" + 0.009*\"court\" + 0.009*\"car\" + 0.008*\"found\" + 0.008*\"drum\"\n",
      "Topic: 2 Word: 0.010*\"turnbul\" + 0.009*\"elect\" + 0.007*\"labor\" + 0.006*\"marriag\" + 0.006*\"abus\" + 0.006*\"$\" + 0.006*\"liber\" + 0.006*\"abbott\" + 0.006*\"malcolm\" + 0.006*\"royal\"\n",
      "Topic: 3 Word: 0.015*\"news\" + 0.011*\"abc\" + 0.011*\"rural\" + 0.009*\"nrl\" + 0.008*\"christma\" + 0.008*\"sport\" + 0.008*\"nation\" + 0.007*\"friday\" + 0.007*\"septemb\" + 0.007*\"peter\"\n",
      "Topic: 4 Word: 0.008*\"grandstand\" + 0.007*\"us\" + 0.006*\"islam\" + 0.006*\"kill\" + 0.006*\"terror\" + 0.005*\"refuge\" + 0.005*\"syria\" + 0.005*\"australian\" + 0.005*\"australia\" + 0.005*\"attack\"\n",
      "Topic: 5 Word: 0.007*\"stori\" + 0.007*\"decemb\" + 0.006*\"quiz\" + 0.005*\":\" + 0.005*\"survey\" + 0.005*\"patient\" + 0.005*\"grand\" + 0.005*\"anim\" + 0.004*\"afl\" + 0.004*\"wait\"\n",
      "Topic: 6 Word: 0.023*\"countri\" + 0.021*\"hour\" + 0.011*\"podcast\" + 0.007*\"wa\" + 0.007*\"nsw\" + 0.006*\"rural\" + 0.005*\"sa\" + 0.005*\"univers\" + 0.005*\"jame\" + 0.005*\"qld\"\n",
      "Topic: 7 Word: 0.012*\"govern\" + 0.006*\"mine\" + 0.006*\"plan\" + 0.005*\"council\" + 0.005*\"octob\" + 0.005*\"new\" + 0.005*\"say\" + 0.005*\"novemb\" + 0.005*\"rio\" + 0.004*\"fund\"\n",
      "Topic: 8 Word: 0.012*\"north\" + 0.011*\"queensland\" + 0.010*\"market\" + 0.007*\"share\" + 0.007*\"south\" + 0.007*\"west\" + 0.007*\"whi\" + 0.006*\"price\" + 0.006*\"australian\" + 0.006*\"rise\"\n",
      "Topic: 9 Word: 0.012*\"donald\" + 0.011*\"interview\" + 0.007*\"rugbi\" + 0.007*\"david\" + 0.006*\"michael\" + 0.006*\"weather\" + 0.005*\"mount\" + 0.005*\"festiv\" + 0.004*\"music\" + 0.004*\"origin\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5366288423538208\t \n",
      "Topic: 0.012*\"north\" + 0.011*\"queensland\" + 0.010*\"market\" + 0.007*\"share\" + 0.007*\"south\" + 0.007*\"west\" + 0.007*\"whi\" + 0.006*\"price\" + 0.006*\"australian\" + 0.006*\"rise\"\n",
      "\n",
      "Score: 0.30329087376594543\t \n",
      "Topic: 0.007*\"stori\" + 0.007*\"decemb\" + 0.006*\"quiz\" + 0.005*\":\" + 0.005*\"survey\" + 0.005*\"patient\" + 0.005*\"grand\" + 0.005*\"anim\" + 0.004*\"afl\" + 0.004*\"wait\"\n",
      "\n",
      "Score: 0.02001289092004299\t \n",
      "Topic: 0.015*\"news\" + 0.011*\"abc\" + 0.011*\"rural\" + 0.009*\"nrl\" + 0.008*\"christma\" + 0.008*\"sport\" + 0.008*\"nation\" + 0.007*\"friday\" + 0.007*\"septemb\" + 0.007*\"peter\"\n",
      "\n",
      "Score: 0.020012356340885162\t \n",
      "Topic: 0.023*\"countri\" + 0.021*\"hour\" + 0.011*\"podcast\" + 0.007*\"wa\" + 0.007*\"nsw\" + 0.006*\"rural\" + 0.005*\"sa\" + 0.005*\"univers\" + 0.005*\"jame\" + 0.005*\"qld\"\n",
      "\n",
      "Score: 0.020010607317090034\t \n",
      "Topic: 0.010*\"turnbul\" + 0.009*\"elect\" + 0.007*\"labor\" + 0.006*\"marriag\" + 0.006*\"abus\" + 0.006*\"$\" + 0.006*\"liber\" + 0.006*\"abbott\" + 0.006*\"malcolm\" + 0.006*\"royal\"\n",
      "\n",
      "Score: 0.020010491833090782\t \n",
      "Topic: 0.012*\"govern\" + 0.006*\"mine\" + 0.006*\"plan\" + 0.005*\"council\" + 0.005*\"octob\" + 0.005*\"new\" + 0.005*\"say\" + 0.005*\"novemb\" + 0.005*\"rio\" + 0.004*\"fund\"\n",
      "\n",
      "Score: 0.02000926434993744\t \n",
      "Topic: 0.022*\"man\" + 0.015*\"polic\" + 0.014*\"charg\" + 0.012*\"murder\" + 0.011*\"woman\" + 0.011*\"crash\" + 0.009*\"court\" + 0.009*\"car\" + 0.008*\"found\" + 0.008*\"drum\"\n",
      "\n",
      "Score: 0.020008377730846405\t \n",
      "Topic: 0.008*\"grandstand\" + 0.007*\"us\" + 0.006*\"islam\" + 0.006*\"kill\" + 0.006*\"terror\" + 0.005*\"refuge\" + 0.005*\"syria\" + 0.005*\"australian\" + 0.005*\"australia\" + 0.005*\"attack\"\n",
      "\n",
      "Score: 0.020008202642202377\t \n",
      "Topic: 0.021*\"trump\" + 0.019*\":\" + 0.010*\"australia\" + 0.009*\"day\" + 0.007*\"live\" + 0.007*\"world\" + 0.006*\"test\" + 0.006*\"energi\" + 0.006*\"win\" + 0.006*\"juli\"\n",
      "\n",
      "Score: 0.0200081504881382\t \n",
      "Topic: 0.012*\"donald\" + 0.011*\"interview\" + 0.007*\"rugbi\" + 0.007*\"david\" + 0.006*\"michael\" + 0.006*\"weather\" + 0.005*\"mount\" + 0.005*\"festiv\" + 0.004*\"music\" + 0.004*\"origin\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.33752818000333545\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.019*\"govern\" + 0.016*\"hill\" + 0.016*\"hunter\" + 0.013*\"station\" + 0.013*\"novemb\" + 0.012*\"energi\" + 0.010*\"project\" + 0.010*\"ga\" + 0.009*\"billion\" + 0.009*\"capit\"\n",
      "Topic: 1 Word: 0.020*\"royal\" + 0.018*\"whi\" + 0.017*\"commiss\" + 0.014*\"rugbi\" + 0.012*\"video\" + 0.011*\"shot\" + 0.009*\"rape\" + 0.008*\"polic\" + 0.008*\"homeless\" + 0.008*\"invest\"\n",
      "Topic: 2 Word: 0.026*\"turnbul\" + 0.014*\"monday\" + 0.014*\"stori\" + 0.014*\"yo\" + 0.011*\"white\" + 0.010*\"major\" + 0.010*\"india\" + 0.010*\"insid\" + 0.009*\"fiji\" + 0.008*\"clinton\"\n",
      "Topic: 3 Word: 0.016*\"health\" + 0.014*\"speak\" + 0.013*\"mental\" + 0.011*\"smith\" + 0.010*\"retir\" + 0.010*\"png\" + 0.009*\"univers\" + 0.008*\"memori\" + 0.008*\"manu\" + 0.008*\"pari\"\n",
      "Topic: 4 Word: 0.018*\"price\" + 0.017*\"market\" + 0.015*\"rate\" + 0.015*\"farm\" + 0.014*\"share\" + 0.014*\"dollar\" + 0.012*\"rise\" + 0.010*\"care\" + 0.010*\"age\" + 0.010*\"newcastl\"\n",
      "Topic: 5 Word: 0.025*\"man\" + 0.021*\"interview\" + 0.021*\"murder\" + 0.020*\"charg\" + 0.016*\"donald\" + 0.015*\"sex\" + 0.013*\"assault\" + 0.012*\"court\" + 0.012*\"polic\" + 0.012*\"hobart\"\n",
      "Topic: 6 Word: 0.018*\"violenc\" + 0.015*\"ash\" + 0.014*\"action\" + 0.013*\"liber\" + 0.013*\"domest\" + 0.013*\"decemb\" + 0.011*\"legal\" + 0.010*\"outback\" + 0.010*\"islam\" + 0.010*\"suicid\"\n",
      "Topic: 7 Word: 0.030*\"tasmania\" + 0.019*\"week\" + 0.017*\"rio\" + 0.013*\"polit\" + 0.011*\"next\" + 0.011*\"music\" + 0.009*\"philippin\" + 0.009*\"honour\" + 0.008*\"exchang\" + 0.008*\"worri\"\n",
      "Topic: 8 Word: 0.036*\"queensland\" + 0.030*\"south\" + 0.026*\"north\" + 0.017*\"west\" + 0.015*\"christma\" + 0.012*\"korea\" + 0.010*\"refuge\" + 0.010*\"central\" + 0.009*\"australia\" + 0.009*\"east\"\n",
      "Topic: 9 Word: 0.037*\"rural\" + 0.019*\"news\" + 0.015*\"nation\" + 0.015*\"john\" + 0.014*\"cricket\" + 0.014*\"live\" + 0.013*\"thursday\" + 0.010*\"zealand\" + 0.009*\"origin\" + 0.008*\"qld\"\n",
      "Topic: 10 Word: 0.013*\"septemb\" + 0.013*\"cattl\" + 0.013*\"wednesday\" + 0.012*\"western\" + 0.011*\"season\" + 0.011*\"histori\" + 0.010*\"thi\" + 0.010*\"export\" + 0.009*\"georg\" + 0.008*\"box\"\n",
      "Topic: 11 Word: 0.021*\"abus\" + 0.015*\"sport\" + 0.014*\"student\" + 0.010*\"educ\" + 0.010*\"foreign\" + 0.009*\"coal\" + 0.009*\"child\" + 0.009*\"church\" + 0.009*\"school\" + 0.008*\"resign\"\n",
      "Topic: 12 Word: 0.015*\"asylum\" + 0.013*\"seeker\" + 0.013*\"old\" + 0.011*\"reform\" + 0.011*\"dairi\" + 0.011*\"know\" + 0.010*\"paul\" + 0.010*\"remot\" + 0.009*\"kimberley\" + 0.008*\"contract\"\n",
      "Topic: 13 Word: 0.045*\"countri\" + 0.041*\"hour\" + 0.013*\"peter\" + 0.011*\"ice\" + 0.011*\"drive\" + 0.010*\"wa\" + 0.010*\"footag\" + 0.010*\"father\" + 0.009*\"detent\" + 0.009*\"doe\"\n",
      "Topic: 14 Word: 0.017*\"nrl\" + 0.014*\"street\" + 0.014*\"juli\" + 0.013*\"friday\" + 0.013*\"dog\" + 0.011*\"vs\" + 0.010*\"disabl\" + 0.010*\"april\" + 0.010*\"result\" + 0.009*\"wild\"\n",
      "Topic: 15 Word: 0.019*\"coast\" + 0.016*\"gold\" + 0.013*\"climat\" + 0.011*\"june\" + 0.010*\"pacif\" + 0.010*\"indonesia\" + 0.009*\"polic\" + 0.008*\"fire\" + 0.008*\"drone\" + 0.008*\"inquest\"\n",
      "Topic: 16 Word: 0.018*\"victorian\" + 0.016*\"miss\" + 0.015*\"search\" + 0.014*\"found\" + 0.014*\"octob\" + 0.013*\"mother\" + 0.013*\"bodi\" + 0.011*\"kid\" + 0.009*\"beach\" + 0.009*\"murray\"\n",
      "Topic: 17 Word: 0.019*\"drum\" + 0.016*\"abc\" + 0.015*\"final\" + 0.014*\"cup\" + 0.013*\"world\" + 0.013*\"win\" + 0.012*\"grandstand\" + 0.011*\"abbott\" + 0.009*\"afl\" + 0.008*\"st\"\n",
      "Topic: 18 Word: 0.015*\"michael\" + 0.013*\"syria\" + 0.012*\"social\" + 0.010*\"human\" + 0.008*\"femal\" + 0.008*\"reveal\" + 0.008*\"mount\" + 0.008*\"hors\" + 0.008*\"camp\" + 0.008*\"cancer\"\n",
      "Topic: 19 Word: 0.026*\"crash\" + 0.021*\"car\" + 0.011*\"driver\" + 0.010*\"injur\" + 0.009*\"explain\" + 0.009*\"die\" + 0.009*\"plane\" + 0.008*\"road\" + 0.008*\"syrian\" + 0.008*\"solar\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.3731153590198484\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4759197352623956\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=35, id2word=dictionary)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.8491633194086815\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=45, id2word=dictionary)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.8491633194086815\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=55, id2word=dictionary)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=df6['headline_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
